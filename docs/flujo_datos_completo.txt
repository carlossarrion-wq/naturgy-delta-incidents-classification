================================================================================
üìä FLUJO DE DATOS COMPLETO - SISTEMA CLASIFICADOR DE INCIDENCIAS NATURGY DELTA
================================================================================

Fecha de documentaci√≥n: 27/10/2025
Versi√≥n del sistema: Refactorizada
Autor: Sistema de an√°lisis autom√°tico

================================================================================
üéØ RESUMEN EJECUTIVO
================================================================================

Este documento describe de manera exhaustiva el flujo completo de datos en el 
Sistema Clasificador de Incidencias Naturgy Delta, desde la entrada de datos 
hasta la generaci√≥n de reportes finales. El sistema procesa incidencias t√©cnicas 
y las clasifica autom√°ticamente en categor√≠as sem√°nticamente coherentes.

COMPONENTES PRINCIPALES:
- Preprocesador de texto (TextPreprocessor)
- Extractor de entidades (EntityExtractor)
- Motor de clustering (IncidentClusterer)
- Clasificador predictivo (PredictiveClassifier)
- Motor de nomenclatura (CategoryNamingEngine)
- Gestor de salidas (OutputManager)

================================================================================
üìã FLUJO DE DATOS DETALLADO - PASO A PASO
================================================================================

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 1: ENTRADA Y CARGA DE DATOS                                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üî∏ PASO 1.1: Carga del archivo de datos
   ‚Ä¢ ENTRADA: Archivo Excel (infomation.xlsx)
   ‚Ä¢ UBICACI√ìN: Directorio ra√≠z del proyecto (/Users/samuel/Desktop/Clasificador V1)
   ‚Ä¢ FORMATO: Excel (.xlsx) con m√∫ltiples columnas
   ‚Ä¢ COLUMNAS PRINCIPALES:
     - Ticket ID: Identificador √∫nico de la incidencia
     - Resumen: Descripci√≥n principal del problema
     - Notas: Informaci√≥n adicional t√©cnica
     - Tipo de ticket: Clasificaci√≥n original (INCIDENCIA, PETICION, CONSULTA)
     - Resoluci√≥n: Descripci√≥n de la soluci√≥n aplicada
     - Otras columnas: Informaci√≥n complementaria disponible
   
   ‚Ä¢ M√âTODO: pd.read_excel(data_path)
   ‚Ä¢ SALIDA: DataFrame de pandas con todos los registros

üî∏ PASO 1.2: Validaci√≥n y filtrado inicial
   ‚Ä¢ ENTRADA: DataFrame completo
   ‚Ä¢ PROCESO: 
     - Verificaci√≥n de columnas requeridas
     - Eliminaci√≥n de registros con campos vac√≠os cr√≠ticos
     - Validaci√≥n de integridad de datos
   ‚Ä¢ CRITERIOS DE FILTRADO:
     - Resumen no puede estar vac√≠o
     - Ticket ID debe existir
     - Al menos una columna de texto adicional presente
   ‚Ä¢ SALIDA: DataFrame limpio y validado

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 2: PREPROCESAMIENTO DE TEXTO                                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üî∏ PASO 2.1: Combinaci√≥n de campos de texto
   ‚Ä¢ ENTRADA: DataFrame validado
   ‚Ä¢ PROCESO: Clase TextPreprocessor._combine_text_columns()
   ‚Ä¢ CAMPOS COMBINADOS:
     - Resumen (peso principal)
     - Notas (informaci√≥n t√©cnica)
     - Tipo de ticket
     - Resoluci√≥n
     - Otros campos de texto disponibles
   ‚Ä¢ M√âTODO: Concatenaci√≥n con espacios separadores
   ‚Ä¢ SALIDA: Serie de pandas 'combined_text'

üî∏ PASO 2.2: Limpieza y normalizaci√≥n de texto
   ‚Ä¢ ENTRADA: combined_text
   ‚Ä¢ PROCESO: TextPreprocessor._process_text()
   ‚Ä¢ OPERACIONES:
     1. Conversi√≥n a min√∫sculas
     2. Eliminaci√≥n de caracteres especiales
     3. Normalizaci√≥n de espacios m√∫ltiples
     4. Eliminaci√≥n de stop words espec√≠ficas:
        - Saludos: "buenos d√≠as", "cordial saludo"
        - Cortes√≠as: "gracias", "un saludo", "favor"
        - Administrativo: "adjunto", "env√≠o", "estimado"
     5. Aplicaci√≥n de sinonimias:
        - fallo ‚Üí error
        - incidencia ‚Üí error
        - problema ‚Üí error
        - cancelaci√≥n ‚Üí baja
        - activaci√≥n ‚Üí alta
        - cambiar ‚Üí modificar
   ‚Ä¢ SALIDA: Serie 'processed_text' limpia y normalizada

üî∏ PASO 2.3: Extracci√≥n de entidades espec√≠ficas
   ‚Ä¢ ENTRADA: combined_text
   ‚Ä¢ PROCESO: EntityExtractor.extract_entities()
   ‚Ä¢ PATRONES DE EXTRACCI√ìN:
     - CUPS: 'ES\d{4}\d{4}\d{4}\d{4}[A-Z]{2}\d[A-Z]'
     - Solicitudes: 'R\d{2}-\d+', 'REQ\d+', 'OFL\d+'
     - Fechas: '\d{1,2}[/-]\d{1,2}[/-]\d{2,4}'
     - Productos: 'bono social', 'cuidahogar', 'rl1', 'tur vulnerable'
     - Estados: 'activo', 'inactivo', 'pendiente', 'bloqueado'
   ‚Ä¢ SALIDA: Diccionario de entidades por registro

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 3: VECTORIZACI√ìN Y AN√ÅLISIS SEM√ÅNTICO                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üî∏ PASO 3.1: Vectorizaci√≥n TF-IDF
   ‚Ä¢ ENTRADA: processed_text (textos limpios)
   ‚Ä¢ PROCESO: TfidfVectorizer de sklearn
   ‚Ä¢ PAR√ÅMETROS:
     - max_features: 8000 (m√°ximo vocabulario)
     - min_df: 3 (palabra debe aparecer al menos 3 veces)
     - max_df: 0.7 (palabra no debe aparecer en m√°s del 70% documentos)
     - ngram_range: (1, 2) (palabras individuales y bigramas)
     - stop_words: None (ya filtradas en preproceso)
   ‚Ä¢ PROCESO INTERNO:
     1. Construcci√≥n del vocabulario
     2. C√°lculo de frecuencias de t√©rminos (TF)
     3. C√°lculo de frecuencia inversa de documentos (IDF)
     4. Multiplicaci√≥n TF √ó IDF
   ‚Ä¢ SALIDA: Matriz esparsa X de dimensiones [n_registros, 8000]

üî∏ PASO 3.2: An√°lisis de clustering inicial
   ‚Ä¢ ENTRADA: Matriz TF-IDF X
   ‚Ä¢ PROCESO: IncidentClusterer._find_optimal_clusters()
   ‚Ä¢ DETERMINACI√ìN DEL N√öMERO DE CLUSTERS:
     - C√°lculo basado en tama√±o del dataset:
       * >3000 registros ‚Üí m√°ximo 25 clusters
       * >1000 registros ‚Üí m√°ximo 15 clusters  
       * <1000 registros ‚Üí m√°ximo 10 clusters
     - M√≠nimo de registros por cluster: 20
   ‚Ä¢ EVALUACI√ìN DE CALIDAD:
     - C√°lculo de inercia para diferentes valores de k
     - C√°lculo de silhouette score
     - Selecci√≥n √≥ptima balanceando coherencia y diversidad
   ‚Ä¢ SALIDA: N√∫mero √≥ptimo de clusters (k_optimal)

üî∏ PASO 3.3: Ejecuci√≥n del clustering
   ‚Ä¢ ENTRADA: Matriz X, k_optimal
   ‚Ä¢ PROCESO: KMeans clustering
   ‚Ä¢ PAR√ÅMETROS:
     - n_clusters: k_optimal
     - random_state: 42 (reproducibilidad)
     - n_init: 10 (m√∫ltiples inicializaciones)
     - max_iter: 300 (m√°ximo iteraciones)
   ‚Ä¢ PROCESO INTERNO:
     1. Inicializaci√≥n aleatoria de centroides
     2. Asignaci√≥n de puntos al centroide m√°s cercano
     3. Rec√°lculo de centroides
     4. Iteraci√≥n hasta convergencia
   ‚Ä¢ SALIDA: Array de etiquetas cluster_labels

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 4: AN√ÅLISIS Y GENERACI√ìN DE CATEGOR√çAS                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üî∏ PASO 4.1: An√°lisis de clusters individuales
   ‚Ä¢ ENTRADA: DataFrame, textos procesados, cluster_labels
   ‚Ä¢ PROCESO: Para cada cluster_id √∫nico:
   
   4.1.1 Extracci√≥n de palabras clave distintivas:
   ‚Ä¢ M√âTODO: _extract_distinctive_keywords()
   ‚Ä¢ PROCESO:
     - Tokenizaci√≥n del texto combinado del cluster
     - Filtrado de stop words expandidas (80+ palabras)
     - Conteo de frecuencias de palabras significativas
     - Selecci√≥n de top 15 palabras m√°s distintivas
   
   4.1.2 An√°lisis de patrones de contenido:
   ‚Ä¢ ENTRADA: Texto procesado del cluster
   ‚Ä¢ PROCESO: Identificaci√≥n de patrones t√©cnicos y funcionales
   ‚Ä¢ SALIDA: Patrones m√°s frecuentes identificados autom√°ticamente
   
   4.1.3 An√°lisis de tipos de ticket:
   ‚Ä¢ ENTRADA: Campo 'Tipo de ticket'
   ‚Ä¢ PROCESO: Distribuci√≥n de INCIDENCIA/PETICION/CONSULTA
   ‚Ä¢ SALIDA: Tipos principales por frecuencia

üî∏ PASO 4.2: Generaci√≥n de nomenclatura sem√°ntica
   ‚Ä¢ ENTRADA: Informaci√≥n del cluster (palabras clave, patrones, contexto)
   ‚Ä¢ PROCESO: CategoryNamingEngine.generate_semantic_name()
   ‚Ä¢ PATRONES T√âCNICOS IDENTIFICADOS:
     1. Infraestructura: servidor, red, conexi√≥n, servicio
     2. Datos: carga, actualizaci√≥n, masiva, informaci√≥n
     3. Comunicaci√≥n: correo, mensaje, notificaci√≥n, env√≠o
     4. Procesos: batch, job, autom√°tico, programado
     5. Consultas: b√∫squeda, listado, extracci√≥n, reporte
     6. Errores: fallo, excepci√≥n, timeout, crash
     7. Facturaci√≥n: factura, cobro, pago, recibo
     8. Contratos: alta, baja, modificaci√≥n, gesti√≥n
   
   ‚Ä¢ MODIFICADORES DE CONTEXTO:
     - Cr√≠tico: urgente, bloqueante, alto
     - Masivo: m√∫ltiple, lote, bulk
     - Autom√°tico: batch, programado, scheduled
     - Manual: individual, espec√≠fico, puntual
   
   ‚Ä¢ ALGORITMO DE NOMENCLATURA:
     1. Identificar patr√≥n t√©cnico principal (scoring por keywords)
     2. Identificar modificador de contexto
     3. Generar nombre base sem√°nticamente coherente
     4. Aplicar modificadores y especificadores
     5. Validar unicidad y legibilidad

üî∏ PASO 4.3: Generaci√≥n de descripciones t√©cnicas
   ‚Ä¢ ENTRADA: Cluster analisado + nombre sem√°ntico
   ‚Ä¢ PROCESO: _generate_enhanced_description()
   ‚Ä¢ ELEMENTOS DE LA DESCRIPCI√ìN:
     1. Contexto num√©rico: n√∫mero de incidencias
     2. Contexto funcional: basado en nombre sem√°ntico
     3. Patrones t√©cnicos: an√°lisis de palabras clave distintivas
     4. Caracter√≠sticas espec√≠ficas: an√°lisis de contenido del texto
   ‚Ä¢ EJEMPLO REAL:
     "Categor√≠a 'Errores Sistema Critico Frecuentes' que agrupa 1089 
     incidencias relacionadas con fallos t√©cnicos, excepciones y errores 
     del sistema. T√©rminos t√©cnicos frecuentes: atlas, error, delta, cups."

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 5: CLASIFICACI√ìN PREDICTIVA Y ENTRENAMIENTO                           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üî∏ PASO 5.1: Preparaci√≥n de datos para ML
   ‚Ä¢ ENTRADA: DataFrame procesado, cluster_labels
   ‚Ä¢ PROCESO: PredictiveClassifier.train_model()
   ‚Ä¢ PREPARACI√ìN DE FEATURES:
     - Reutilizaci√≥n de matriz TF-IDF como features (X)
     - Uso de cluster_labels como target (y)
     - Codificaci√≥n de etiquetas con LabelEncoder
   ‚Ä¢ DIVISI√ìN DE DATOS:
     - 80% entrenamiento, 20% prueba
     - Estratificaci√≥n por cluster para balance
     - random_state=42 para reproducibilidad

üî∏ PASO 5.2: Entrenamiento del modelo predictivo
   ‚Ä¢ ENTRADA: X_train, y_train
   ‚Ä¢ ALGORITMO: RandomForestClassifier
   ‚Ä¢ PAR√ÅMETROS:
     - n_estimators: 100 (√°rboles en el bosque)
     - random_state: 42
     - n_jobs: -1 (paralelizaci√≥n)
   ‚Ä¢ PROCESO DE ENTRENAMIENTO:
     1. Construcci√≥n de 100 √°rboles de decisi√≥n
     2. Entrenamiento con muestras bootstrap
     3. Selecci√≥n aleatoria de features por nodo
     4. Agregaci√≥n de predicciones por votaci√≥n
   ‚Ä¢ M√âTRICAS CALCULADAS:
     - Accuracy en entrenamiento
     - Accuracy en prueba  
     - Cross-validation score (5-fold)

üî∏ PASO 5.3: Sistema de reglas sem√°nticas espec√≠ficas
   ‚Ä¢ ENTRADA: Texto de nueva incidencia
   ‚Ä¢ PROCESO: _apply_semantic_rules()
   ‚Ä¢ DICCIONARIO DE REGLAS (20 CATEGOR√çAS ESPEC√çFICAS):
   
   1. Gesti√≥n de CUPS:
      - Keywords: "alta cups", "baja cups", "activar cups", "cups"
      - Confianza: 0.70-0.95 seg√∫n coincidencias
   
   2. Montaje/Desmontaje/Equipos:
      - Keywords: "montaje", "desmontaje", "aparato", "equipo de lectura"
      - Criticidad: Alta
   
   3. Errores de c√°lculo/facturaci√≥n:
      - Keywords: "error al calcular", "tipdet", "passthrough", "java.lang.nullpointerexception"
      - Criticidad: Alta
   
   4. Estados de c√°lculo/facturaci√≥n:
      - Keywords: "no calculable", "calculable", "bloqueado", "desbloquear"
      - Criticidad: Media
   
   5. Lecturas y mediciones:
      - Keywords: "lectura", "medici√≥n", "nm3", "pcs", "solape"
      - Criticidad: Media
   
   6. Datos de cliente y contratos:
      - Keywords: "direcci√≥n", "titular", "nif", "email", "tel√©fono"
      - Criticidad: Media
   
   7. Cambio de titularidad:
      - Keywords: "cambio titular", "subrogaci√≥n"
      - Criticidad: Media
   
   8. Ofertas y contrataci√≥n:
      - Keywords: "oferta", "validar oferta", "firmar oferta", "contrataci√≥n"
      - Criticidad: Media
   
   9. Tarifas y productos:
      - Keywords: "tarifa", "producto", "cuida b√°sico", "mantenimiento"
      - Criticidad: Media
   
   10. Bono social:
       - Keywords: "bono social", "vulnerable", "renovaci√≥n bono"
       - Criticidad: Media
   
   [... 10 categor√≠as adicionales con patrones espec√≠ficos]
   
   ‚Ä¢ ALGORITMO DE MATCHING:
     1. Scoring por coincidencias de keywords
     2. C√°lculo de confianza basado en n√∫mero de matches
     3. Selecci√≥n de categor√≠a con mayor score
     4. Retorno de clasificaci√≥n con metadatos completos

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 6: GENERACI√ìN DE SALIDAS Y REPORTES                                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üî∏ PASO 6.1: Estructuraci√≥n de resultados
   ‚Ä¢ ENTRADA: Categor√≠as generadas, m√©tricas del modelo
   ‚Ä¢ PROCESO: _save_results_organized()
   ‚Ä¢ ESTRUCTURA DE CARPETAS CREADA:
     
     outputs/
     ‚îú‚îÄ‚îÄ models/
     ‚îÇ   ‚îî‚îÄ‚îÄ naturgy_model_YYYYMMDD_HHMMSS.pkl
     ‚îú‚îÄ‚îÄ data/
     ‚îÇ   ‚îî‚îÄ‚îÄ analisis_completo_naturgy.json
     ‚îú‚îÄ‚îÄ reports/
     ‚îÇ   ‚îú‚îÄ‚îÄ reporte_analisis_naturgy.txt
     ‚îÇ   ‚îî‚îÄ‚îÄ resumen_ejecutivo.txt
     ‚îî‚îÄ‚îÄ logs/
         ‚îî‚îÄ‚îÄ (archivos de registro)

üî∏ PASO 6.2: Generaci√≥n del modelo serializado
   ‚Ä¢ ENTRADA: Todos los componentes entrenados
   ‚Ä¢ CONTENIDO DEL MODELO (.pkl):
     - Preprocesador configurado
     - Clusterer con centroides
     - Clasificador entrenado
     - Extractor de entidades
     - Tipos de incidencia definidos
     - Configuraci√≥n del sistema
     - Timestamp de creaci√≥n
   ‚Ä¢ M√âTODO: pickle.dump()
   ‚Ä¢ TAMA√ëO T√çPICO: ~50-100 MB

üî∏ PASO 6.3: Generaci√≥n de an√°lisis JSON completo
   ‚Ä¢ ARCHIVO: analisis_completo_naturgy.json
   ‚Ä¢ ESTRUCTURA:
     
     {
       "metadata": {
         "fecha_analisis": "2025-10-24T14:11:25.815338",
         "total_categorias": 17,
         "metodo_clustering": "KMeans",
         "metodo_clasificacion": "random_forest"
       },
       "tipos_de_incidencia": {
         "categoria_key": {
           "nombre": "Nombre Sem√°ntico",
           "descripcion": "Descripci√≥n t√©cnica detallada",
           "num_incidencias": 123,
           "palabras_clave": ["palabra1", "palabra2", ...],
           "tipos_principales": ["INCIDENCIA", "PETICION"],
           "ejemplos": [
             {
               "id": "INC000014898139",
               "resumen": "Texto del resumen...",
               "tipo_ticket": "INCIDENCIA"
             }
           ],
           "patrones_identificados": ["Patr√≥n1", "Patr√≥n2"],
           "nivel_criticidad": "Alta|Media|Baja"
         }
       },
       "metricas_modelo": {
         "silhouette_score": 0.0865,
         "model_accuracy": 0.9259,
         "model_cv_score": 0.9259,
         "num_clusters": 25,
         "coverage": 1.0
       },
       "cluster_info": {
         "num_clusters": 25,
         "silhouette_score": 0.0865,
         "cluster_sizes": { "16": 1089, "1": 408, ... }
       }
     }

üî∏ PASO 6.4: Generaci√≥n de reportes legibles
   ‚Ä¢ REPORTE COMPLETO (reporte_analisis_naturgy.txt):
     - Cabecera con metadatos del an√°lisis
     - Estad√≠sticas generales del modelo
     - Listado detallado de todas las categor√≠as:
       * Nombre y descripci√≥n
       * N√∫mero de incidencias y criticidad
       * Palabras clave y patrones identificados
       * Ejemplos representativos con IDs reales
     - Formato: 80 caracteres de ancho, secciones delimitadas
   
   ‚Ä¢ RESUMEN EJECUTIVO (resumen_ejecutivo.txt):
     - Resultados clave en formato ejecutivo
     - Top 5 categor√≠as por volumen
     - Estad√≠sticas de criticidad
     - Recomendaciones operativas:
       * Priorizar categor√≠as de alta criticidad
       * Implementar automatizaci√≥n en categor√≠as frecuentes
       * Desarrollar procedimientos espec√≠ficos

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ FASE 7: CLASIFICACI√ìN DE NUEVAS INCIDENCIAS                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

üî∏ PASO 7.1: Flujo de clasificaci√≥n en tiempo real
   ‚Ä¢ ENTRADA: Texto de nueva incidencia + campos opcionales
   ‚Ä¢ PROCESO: classify_incident()
   ‚Ä¢ FLUJO COMPLETO:
   
   1. Aplicaci√≥n de reglas sem√°nticas (pre-clasificaci√≥n):
      ‚Ä¢ B√∫squeda en diccionario de 20 categor√≠as espec√≠ficas
      ‚Ä¢ Scoring por coincidencias de keywords
      ‚Ä¢ Retorno inmediato si confianza > umbral
   
   2. Si no hay match en reglas sem√°nticas:
      ‚Ä¢ Creaci√≥n de DataFrame temporal
      ‚Ä¢ Aplicaci√≥n de preprocesamiento completo
      ‚Ä¢ Extracci√≥n de entidades
      ‚Ä¢ Vectorizaci√≥n con TF-IDF entrenado
      ‚Ä¢ Predicci√≥n con RandomForest
      ‚Ä¢ C√°lculo de confianza con predict_proba
   
   3. Enriquecimiento de resultado:
      ‚Ä¢ Mapeo a informaci√≥n de categor√≠a
      ‚Ä¢ Extracci√≥n de metadatos
      ‚Ä¢ Generaci√≥n de explicaci√≥n

üî∏ PASO 7.2: Sistema de casos de prueba
   ‚Ä¢ ARCHIVO: test_classifier.py
   ‚Ä¢ PROCESO: TestCaseGenerator.run_complete_test()
   ‚Ä¢ FLUJO COMPLETO:
   
   1. Separaci√≥n de datos:
      ‚Ä¢ Selecci√≥n aleatoria de 100 casos para prueba
      ‚Ä¢ Resto de datos para entrenamiento
      ‚Ä¢ Guardado de casos de prueba originales
   
   2. Entrenamiento independiente:
      ‚Ä¢ Creaci√≥n de clasificador nuevo
      ‚Ä¢ Entrenamiento solo con datos no-prueba
      ‚Ä¢ Validaci√≥n de entrenamiento exitoso
   
   3. Clasificaci√≥n de casos de prueba:
      ‚Ä¢ Iteraci√≥n sobre cada caso de prueba
      ‚Ä¢ Aplicaci√≥n del flujo completo de clasificaci√≥n
      ‚Ä¢ Captura de errores y handling robusto
   
   4. Generaci√≥n de reportes de prueba:
      ‚Ä¢ Estad√≠sticas de confianza
      ‚Ä¢ Distribuci√≥n por categor√≠as predichas
      ‚Ä¢ Detalle caso por caso con metadatos
      ‚Ä¢ Guardado en JSON y texto plano

================================================================================
üìä M√âTRICAS Y RENDIMIENTO DEL SISTEMA
================================================================================

üî∏ M√âTRICAS DE CLUSTERING:
   ‚Ä¢ Silhouette Score: 0.0865 (rango: -1 a 1, >0 indica clustering v√°lido)
   ‚Ä¢ N√∫mero de clusters: 25 (de m√°ximo 50 configurado)
   ‚Ä¢ Distribuci√≥n de tama√±os: 
     - Cluster m√°s grande: 1089 incidencias
     - Cluster m√°s peque√±o: 23 incidencias
     - Promedio: ~120 incidencias por cluster

üî∏ M√âTRICAS DEL MODELO PREDICTIVO:
   ‚Ä¢ Accuracy: 92.59% (excelente para clasificaci√≥n multiclase)
   ‚Ä¢ Cross-validation Score: 92.59% (consistencia en validaci√≥n cruzada)
   ‚Ä¢ Cobertura: 100% (todos los casos clasificados)

üî∏ DISTRIBUCI√ìN DE CATEGOR√çAS POR VOLUMEN:
   1. Errores Sistema Critico Frecuentes: 1089 incidencias (36.3%)
   2. Gesti√≥n Contratos Automatico Frecuentes: 184 incidencias (6.1%)
   3. Facturaci√≥n Critico Frecuentes: 264 incidencias (8.8%)
   4. Errores Sistema Automatico Frecuentes: 196 incidencias (6.5%)
   5. Gesti√≥n Datos Automatico Frecuentes: 118 incidencias (3.9%)
   [... resto de categor√≠as basadas en an√°lisis de texto ...]

üî∏ DISTRIBUCI√ìN POR CRITICIDAD:
   ‚Ä¢ Alta criticidad: 4 categor√≠as (~45% de incidencias)
   ‚Ä¢ Media criticidad: 8 categor√≠as (~35% de incidencias)  
   ‚Ä¢ Baja criticidad: 5 categor√≠as (~20% de incidencias)

================================================================================
üîß CONFIGURACI√ìN T√âCNICA DEL SISTEMA
================================================================================

üî∏ PAR√ÅMETROS PRINCIPALES:
   ‚Ä¢ max_clusters: 50 (m√°ximo clusters permitidos)
   ‚Ä¢ min_cluster_size: 20 (m√≠nimo incidencias por cluster)
   ‚Ä¢ tfidf_max_features: 8000 (vocabulario m√°ximo)
   ‚Ä¢ tfidf_min_df: 3 (frecuencia m√≠nima de palabra)
   ‚Ä¢ tfidf_max_df: 0.7 (frecuencia m√°xima de palabra)
   ‚Ä¢ random_state: 42 (semilla para reproducibilidad)

üî∏ ALGORITMOS UTILIZADOS:
   ‚Ä¢ Clustering: KMeans con inicializaci√≥n k-means++
   ‚Ä¢ Clasificaci√≥n: RandomForest con 100 estimadores
   ‚Ä¢ Vectorizaci√≥n: TF-IDF con n-gramas (1,2)
   ‚Ä¢ Validaci√≥n: 5-fold cross-validation

üî∏ RECURSOS COMPUTACIONALES:
   ‚Ä¢ Memoria requerida: ~2-4 GB RAM para datasets grandes
   ‚Ä¢ Tiempo de entrenamiento: 5-15 minutos seg√∫n tama√±o
   ‚Ä¢ Tiempo de clasificaci√≥n: <1 segundo por incidencia
   ‚Ä¢ Espacio en disco: ~100-200 MB para modelo completo

================================================================================
üìÅ ESTRUCTURA DE ARCHIVOS GENERADOS
================================================================================

Clasificador V1/
‚îú‚îÄ‚îÄ src/                                    # C√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ naturgy_classifier_refactored.py   # Clasificador principal
‚îÇ   ‚îú‚îÄ‚îÄ semantic_analyzer_refactored.py    # Analizador sem√°ntico
‚îÇ   ‚îî‚îÄ‚îÄ test_classifier.py                 # Script de pruebas
‚îú‚îÄ‚îÄ docs/                                   # Documentaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ flujo_datos_completo.txt           # Este documento
‚îÇ   ‚îú‚îÄ‚îÄ explicacion_centroides_naturgy.txt # Explicaci√≥n t√©cnica
‚îÇ   ‚îî‚îÄ‚îÄ resumen_ejecutivo_proyecto_naturgy.txt # Resumen del proyecto
‚îú‚îÄ‚îÄ sistema_final_naturgy/                  # Salidas del sistema
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analisis_completo_naturgy.json # An√°lisis completo
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ casos_prueba_original.xlsx     # Casos de prueba
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ casos_prueba_resultados.json   # Resultados de pruebas
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ naturgy_model_YYYYMMDD_HHMMSS.pkl # Modelo entrenado
‚îÇ   ‚îú‚îÄ‚îÄ reports/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ casos_prueba_detallado.txt     # Reporte detallado de pruebas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ reporte_analisis_naturgy.txt   # Reporte completo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ resumen_ejecutivo.txt          # Resumen para directivos
‚îÇ   ‚îî‚îÄ‚îÄ logs/                              # Archivos de registro
‚îú‚îÄ‚îÄ infomation.xlsx                         # Datos de entrada
‚îî‚îÄ‚îÄ README.md                              # Documentaci√≥n del proyecto

================================================================================
üöÄ CASOS DE USO Y APLICACI√ìN PR√ÅCTICA
================================================================================

üî∏ CASO DE USO 1: Clasificaci√≥n autom√°tica en tiempo real
   ‚Ä¢ INPUT: Nueva incidencia de usuario
   ‚Ä¢ PROCESO: 
     1. Aplicaci√≥n de reglas sem√°nticas (< 100ms)
     2. Si no hay match, clasificaci√≥n ML (< 1s)
     3. Retorno de categor√≠a + confianza + metadatos
   ‚Ä¢ OUTPUT: Categor√≠a asignada con explicaci√≥n

üî∏ CASO DE USO 2: An√°lisis de tendencias hist√≥ricas
   ‚Ä¢ INPUT: Dataset hist√≥rico de incidencias
   ‚Ä¢ PROCESO: Entrenamiento completo del pipeline
   ‚Ä¢ OUTPUT: 
     - Categor√≠as sem√°nticamente coherentes
     - M√©tricas de calidad
     - Reportes ejecutivos y t√©cnicos

üî∏ CASO DE USO 3: Validaci√≥n y testing del sistema
   ‚Ä¢ INPUT: Dataset con casos de prueba separados
   ‚Ä¢ PROCESO: Entrenamiento + clasificaci√≥n de casos prueba
   ‚Ä¢ OUTPUT: M√©tricas de precisi√≥n y reportes detallados

üî∏ CASO DE USO 4: Monitoreo y mejora continua
   ‚Ä¢ INPUT: Nuevos datasets peri√≥dicos
   ‚Ä¢ PROCESO: Re-entrenamiento y comparaci√≥n de m√©tricas
   ‚Ä¢ OUTPUT: Evoluci√≥n de categor√≠as y precisi√≥n del sistema

================================================================================
‚ö° OPTIMIZACIONES Y MEJORAS IMPLEMENTADAS
================================================================================

üî∏ MEJORAS EN NOMENCLATURA:
   ‚Ä¢ Sistema de nomenclatura sem√°nticamente coherente
   ‚Ä¢ Eliminaci√≥n de nombres gen√©ricos como "Cluster_01"
   ‚Ä¢ Incorporaci√≥n de modificadores contextuales (Cr√≠tico, Masivo, etc.)
   ‚Ä¢ Validaci√≥n de unicidad y legibilidad de nombres

üî∏ MEJORAS EN ORGANIZACI√ìN:
   ‚Ä¢ Estructura de carpetas profesional y organizadas
   ‚Ä¢ Separaci√≥n clara entre modelos, datos, reportes y logs
   ‚Ä¢ Archivos de salida con timestamps para versionado
   ‚Ä¢ Compatibilidad con sistemas de producci√≥n

üî∏ MEJORAS EN ROBUSTEZ:
   ‚Ä¢ Manejo robusto de errores en todas las fases
   ‚Ä¢ Validaci√≥n de datos de entrada
   ‚Ä¢ Fallbacks para casos edge
   ‚Ä¢ Sistema de logging comprensivo

üî∏ MEJORAS EN INTERPRETABILIDAD:
   ‚Ä¢ Reportes ejecutivos para diferentes audiencias
   ‚Ä¢ Ejemplos representativos con IDs reales
   ‚Ä¢ Explicaciones t√©cnicas detalladas
   ‚Ä¢ M√©tricas de confianza por clasificaci√≥n

================================================================================
üìã CONCLUSIONES Y RECOMENDACIONES
================================================================================

üî∏ FORTALEZAS DEL SISTEMA:
   ‚úÖ Alta precisi√≥n (92.59%) en clasificaci√≥n autom√°tica
   ‚úÖ Nomenclatura sem√°nticamente coherente y profesional
   ‚úÖ Estructura modular y extensible
   ‚úÖ Manejo robusto de casos edge y errores
   ‚úÖ Reportes completos para diferentes audiencias
   ‚úÖ Sistema de reglas sem√°nticas para casos espec√≠ficos

üî∏ √ÅREAS DE MEJORA FUTURAS:
   üîÑ Incorporaci√≥n de modelos de NLP m√°s avanzados (BERT, transformers)
   üîÑ Sistema de feedback para mejora continua
   üîÑ Integraci√≥n con APIs externas para enriquecimiento de datos
   üîÑ Dashboard web para monitoreo en tiempo real
   üîÑ Sistema de alertas autom√°ticas para categor√≠as cr√≠ticas

üî∏ RECOMENDACIONES OPERATIVAS:
   üìä Ejecutar re-entrenamiento mensual con nuevos datos
   üìä Monitorear m√©tricas de confianza y derivar casos de baja confianza
   üìä Implementar feedback loop con clasificadores humanos
   üìä Priorizar atenci√≥n a categor√≠as de alta criticidad identificadas
   üìä Desarrollar procedimientos espec√≠ficos por categor√≠a

================================================================================
üìû INFORMACI√ìN T√âCNICA ADICIONAL
================================================================================

Sistema desarrollado como parte del proyecto de automatizaci√≥n de clasificaci√≥n
de incidencias t√©cnicas para Naturgy Delta. 

Versi√≥n: Refactorizada y optimizada
Fecha: Octubre 2025
Lenguaje: Python 3.x
Dependencias principales: pandas, scikit-learn, numpy, nltk (opcional)

Para soporte t√©cnico o extensiones del sistema, consultar la documentaci√≥n
adicional en la carpeta docs/ o contactar al equipo de desarrollo.

================================================================================
FIN DEL DOCUMENTO - FLUJO DE DATOS COMPLETO
================================================================================
